{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic's data analysis and machine learning\n",
    "## By Jérémy P. Schneider, consultant at IBM interactive\n",
    "\n",
    "As someone new in this field I decided to take my first challenge with the Titanic dataset from Kaggle (https://www.kaggle.com/c/titanic)\n",
    "\n",
    "## My OS\n",
    "For this work I used a computer with :\n",
    "    * Windows 7\n",
    "    * Intel(R) Core(TM) i5-2500K CPU @ 3.30GHz\n",
    "    * 16 Go RAM (4 x 4 Go)\n",
    "    * NVIDIA GeForce GTX 1050 Ti\n",
    "\n",
    "This notebook will be split in different part :\n",
    "\n",
    "## [Setting our environnement :](#ENV)\n",
    "\n",
    "### [Libraries Import](#lib)\n",
    "### [Personnalized functions and tools](#func)\n",
    "### [Data import](#import)\n",
    "\n",
    "## [Data cleaning :](#CLEAN)\n",
    "### [Data analysis and Handeling missing data](#analysis)\n",
    "### [Converting all data in number](#convert)\n",
    "\n",
    "\n",
    "## [Test and train of a model](#test_train)\n",
    "\n",
    "## [Conclusion and trial over the test sample](#conclusion)\n",
    "\n",
    "<a id=\"ENV\"></a>\n",
    "# Setting our environnement\n",
    "<a id=\"lib\"></a>\n",
    "## Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"func\"></a>\n",
    "## Personnalized functions and tools\n",
    "\n",
    "Since the Titanic dataset contains name with Title, I used the idea of Ertuğrul Demir to create a dictionnary to remplace them (https://www.kaggle.com/datafan07/titanic-eda-and-several-modelling-approaches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_titre = {\n",
    "    'Capt': 'Dr/Clerc/Mil',\n",
    "    'Col': 'Dr/Clerc/Mil',\n",
    "    'Major': 'Dr/Clerc/Mil',\n",
    "    'Jonkheer': 'Honor',\n",
    "    'Don': 'Honor',\n",
    "    'Dona': 'Honor',\n",
    "    'Sir': 'Honor',\n",
    "    'Dr': 'Dr/Clerc/Mil',\n",
    "    'Rev': 'Dr/Clerc/Mil',\n",
    "    'the Countess': 'Honor',\n",
    "    'Mme': 'Mrs',\n",
    "    'Mlle': 'Miss',\n",
    "    'Ms': 'Mrs',\n",
    "    'Mr': 'Mr',\n",
    "    'Mrs': 'Mrs',\n",
    "    'Miss': 'Miss',\n",
    "    'Master': 'Master',\n",
    "    'Lady': 'Honor'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CLEAN\"></a>\n",
    "# Data cleaning\n",
    "\n",
    "<a id=\"analysis\"></a>\n",
    "## Data analysis and Handeling missing data\n",
    "    From Kaggle we know how the data is ordered and it define our goal :\n",
    "\n",
    "The data has been split into two groups:\n",
    "\n",
    "    training set (train.csv)\n",
    "    test set (test.csv)\n",
    "\n",
    "The training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use feature engineering to create new features.\n",
    "\n",
    "The test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
    "\n",
    "We also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\n",
    "\n",
    "### Data Dictionary\n",
    "\n",
    "|Variable\t    |Definition\t        |Key\n",
    "| ------------- |:-----------------:| -----:|\n",
    "|survival \t    |Survival \t        |0 = No, 1 = Yes\n",
    "|pclass \t    |Ticket class \t    |1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "|sex \t        |Sex \t\n",
    "|Age \t        |Age in years \t\n",
    "|sibsp \t        |# of siblings / spouses aboard the Titanic \t\n",
    "|parch \t        |# of parents / children aboard the Titanic \t\n",
    "|ticket         |Ticket number \t\n",
    "|fare \t        |Passenger fare \t\n",
    "|cabin \t        |Cabin number \t\n",
    "|embarked \t    |Port of Embarkation|C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "### Variable Notes\n",
    "\n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "### Checking data\n",
    "\n",
    "If we watch how the data is in our ile, wa saw that the information is correct.\n",
    "\n",
    "* First the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the train data we have 891 rows and 12 column\n"
     ]
    }
   ],
   "source": [
    "print(\"In the train data we have {} rows and {} column\".format(df_train.shape[0], df_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the test data we have 418 rows and 11 column\n"
     ]
    }
   ],
   "source": [
    "print(\"In the test data we have {} rows and {} column\".format(df_test.shape[0], df_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see the two set have the same topology :\n",
    "* int and float for numerical values.\n",
    "* object for text data.\n",
    "\n",
    "We'll need to transform the text data in numerical values in order to feed our machine learning model.\n",
    "\n",
    "After checking the type of the data we use, we need to see where missing values are, to do so we can simply calculated them this way :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.000000\n",
       "Survived       0.000000\n",
       "Pclass         0.000000\n",
       "Name           0.000000\n",
       "Sex            0.000000\n",
       "Age            0.198653\n",
       "SibSp          0.000000\n",
       "Parch          0.000000\n",
       "Ticket         0.000000\n",
       "Fare           0.000000\n",
       "Cabin          0.771044\n",
       "Embarked       0.002245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.000000\n",
       "Pclass         0.000000\n",
       "Name           0.000000\n",
       "Sex            0.000000\n",
       "Age            0.205742\n",
       "SibSp          0.000000\n",
       "Parch          0.000000\n",
       "Ticket         0.000000\n",
       "Fare           0.002392\n",
       "Cabin          0.782297\n",
       "Embarked       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this step we know :\n",
    "* __Cabin__ information is missing in more than 75% of our data, so we'll not use it.\n",
    "* __Age__ information is missing at 20% of the time, we'll try to remplace the missing values\n",
    "* __Embarked__ information is missing several values in the trainset\n",
    "* __Fare__ information is missing serveral values in the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
